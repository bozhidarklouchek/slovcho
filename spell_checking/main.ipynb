{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences:\n",
      "1758815\n",
      "Number of words:\n",
      "736456\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cwd = 'C:/Users/klouc/Desktop/slovcho/spell_checking'\n",
    "\n",
    "sents = pd.read_csv(rf\"{cwd}/sents.csv\",encoding='utf-8')\n",
    "valid_words = pd.read_csv(rf\"{cwd}/single_words_bg.csv\",encoding='utf-8')\n",
    "\n",
    "valid_words_dict = {}\n",
    "for word in list(valid_words['word']):\n",
    "    valid_words_dict[word] = word\n",
    "\n",
    "print(\"Number of sentences:\")\n",
    "print(len(sents.values))\n",
    "print(\"Number of words:\")\n",
    "print(len(valid_words.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tokenise input in clever way\n",
    "# TODO: Dealing with non-cyrillic characters\n",
    "# TODO: How to deal if first word (capitalised but only cause start of sent) is wrong? As in, discerning capital letter\n",
    "\n",
    "import re\n",
    "\n",
    "sent_to_check = 'Възстанието беше тогава'\n",
    "\n",
    "# PRE-PROCESS INPUT\n",
    "\n",
    "# Clear punctuation\n",
    "sent_to_check = sent_to_check\n",
    "sent_to_check = re.sub(\"[?!.,:]\", \"\", sent_to_check)\n",
    "\n",
    "# Tokenise\n",
    "words_to_check = sent_to_check.split(' ')\n",
    "\n",
    "# Lower first character\n",
    "if(ord(words_to_check[0][0]) >= ord('А') and ord(words_to_check[0][0]) <= ord('Я')):\n",
    "     words_to_check[0] = words_to_check[0].lower()\n",
    "# # If beginning word is capitalised and a non-capitalised version exists in the dict, lower it (might be a name)\n",
    "# # Else do not lower\n",
    "# if(ord(words_to_check[0][0]) >= ord('А') and ord(words_to_check[0][0]) <= ord('Я')):\n",
    "#     if(words_to_check[0].lower() in valid_words.values):\n",
    "#         words_to_check[0] = words_to_check[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758815\n",
      "1758763\n"
     ]
    }
   ],
   "source": [
    "# TODO: Break sentences up more as some 'sents' include multiple sentences\n",
    "# TODO: Lowers first letter of sent but what if first word has multiple capitalised letters\n",
    "# TODO: Tokenise sentences in a more clever way\n",
    "\n",
    "# Create unigrams and bigrams from sents\n",
    "\n",
    "# Sents vocab АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЬЮЯабвгдежзийклмнопрстуфхцчшщъьюя1234567890!@#$%^&*()-_=+`~[]{}|;':\"\\,./<>\n",
    "def process_sent(sentence):\n",
    "\n",
    "    replace_with_space_chars = '[!@#$%^&*()-_=+`~{}\\|;\\[\\]\\':\\\"\\,./<>]'\n",
    "\n",
    "    # CLEAN SENTENCES\n",
    "    # Replace some chars with space\n",
    "    sentence = re.sub(replace_with_space_chars, ' ', sentence)\n",
    "    # Replace consecutive spaces with single space\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    # If sent below 10 characters do not consider\n",
    "    if(len(sentence) < 5): return np.nan\n",
    "\n",
    "    # Remove first charatcer if space\n",
    "    if(sentence[0] == ' '): sentence = sentence[1:]\n",
    "    # Lower letter if non-capitlised word exists in dict\n",
    "    first_word = ''\n",
    "    if(sentence.find(' ')):\n",
    "        first_word = sentence[:sentence.find(' ')]\n",
    "    else:\n",
    "        first_word = sentence\n",
    "    if(ord(first_word[0]) >= ord('А') and ord(first_word[0]) <= ord('Я') and (first_word[0].lower() + first_word[1:]) in valid_words_dict):\n",
    "        sentence = sentence[0].lower() + sentence[1:]\n",
    "\n",
    "    # ADD BEGINNING AND CLOSING TAG\n",
    "    sentence = '<s>' + sentence + '</s>'\n",
    "\n",
    "    return sentence\n",
    "    \n",
    "cleaned_sents = sents[\"sent\"].apply(lambda x : process_sent(x))\n",
    "# Drop rows with no content\n",
    "cleaned_sents.dropna(inplace=True)\n",
    "cleaned_sents.reset_index(inplace=True, drop=True)\n",
    "\n",
    "cleaned_sents.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\klouc\\Desktop\\slovcho\\spell_checking\\main.ipynb Cell 4\u001b[0m line \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/klouc/Desktop/slovcho/spell_checking/main.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Get candidates which are valid words\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/klouc/Desktop/slovcho/spell_checking/main.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m valid_candidates \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/klouc/Desktop/slovcho/spell_checking/main.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m candidate \u001b[39min\u001b[39;00m candidates:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/klouc/Desktop/slovcho/spell_checking/main.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mif\u001b[39;00m(candidate \u001b[39min\u001b[39;00m valid_words\u001b[39m.\u001b[39mvalues):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/klouc/Desktop/slovcho/spell_checking/main.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         valid_candidates\u001b[39m.\u001b[39mappend(candidate)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'абвгдежзийклмнопрстуфхцчшщъьюя'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "# Find non-real words and evaluate\n",
    "for word in words_to_check:\n",
    "    if word not in valid_words.values:\n",
    "        candidates = edits1(word)\n",
    "\n",
    "        # Get candidates which are valid words\n",
    "        valid_candidates = []\n",
    "        for candidate in candidates:\n",
    "            if(candidate in valid_words.values):\n",
    "                valid_candidates.append(candidate)\n",
    "        print(valid_candidates)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
